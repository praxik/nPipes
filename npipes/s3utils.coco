# -*- mode: python;-*-
from typing import Union, AnyStr, Optional
import pathlib
import hashlib
import boto3

from .outcome import Outcome, Success, Failure
from .utils.typeshed import pathlike


# I don't like that I can't put proper type annotations on the static function inside
# here. Maybe just need to move the data type into its own module and declare the
# function as free function? That kind of gets the namespacing situation sorted out.
class S3Path:
    """Represents path to an object in AWS S3.
       Two accessible properties: bucket, key; both are strings (str)
       Use str(my_s3_path) to get a nice "s3://bucket/key" string representation.

       Can be instantiated in 3 different ways:

       # copy constructor:
       new_s3_path = S3Path(old_s3_path)

       # bucket and key strings:
       s3_path = S3Path("bucket", "key")

       # bucket and key pathlib.Path's:
       s3_path = S3Path(Path("bucket"), Path("key"))
    """
    def __init__(self, a:Union[S3Path, pathlike], k:Optional[pathlike]=None) -> None:
        if k:
            if isinstance(a, str) or isinstance(a, pathlib.Path):
                self.bucket = str(a)
                self.key = str(k)
            else:
                raise TypeError("When k is provided, a must be either a str or a pathlib.Path")
        else:
            if isinstance(a, S3Path):
                self.bucket = a.bucket
                self.key = a.key
            else:
                _, pth = str(a).split("://")
                bucket, *keyParts = pth.split("/")
                self.bucket = bucket
                self.key = "/".join(keyParts)


    # def from(path):
    #     """Get a new S3Path from either a *str* or an existing *S3Path*
    #     """
    #     if isinstance(path, str):
    #         return S3Path.fromString(path)
    #     else:
    #         return S3Path(path.bucket, path.key)

    # def fromString(path):
    #     _, pth = path.split("://")
    #     bucket, *keyParts = pth.split("/")
    #     return S3Path(bucket,
    #                   keyParts |> "/".join )

    def add(self, path:str) -> S3Path:
        """Adds a new "filename" onto end of path
        """
        return S3Path(self.bucket,
                      self.key |> pathlib.Path |> .joinpath(path) )

    def __str__(self):
        return "s3://{}/{}".format(self.bucket, self.key)


# -> Outcome[str, pathlike]
def downloadFile(remotePath:Union[str, S3Path], localPath:pathlike) -> Outcome:
    """Assumes AWS credentials exist in the environment
       Though the types involved are different, the signature for
       downloadFile, uploadFile, and uploadData follows the same pattern:
       source -> destination -> destination
    """
    s3path = S3Path(remotePath)

    try:
        obj = boto3.resource("s3").Object(s3path.bucket, s3path.key)
        pth = pathlib.Path(localPath)
        # If we already have the current version, don't download it again
        if isCurrent(obj, pth):
            return Success(localPath)
        else:
            preparePath(pth)
            obj.download_file(str(localPath))
            return checkLocal(pth)
    except Exception as err:
        return Failure("Unable to download {}. Reason: {}".format(remotePath, err))


def isCurrent(obj:boto3.S3.Object, pth:pathlib.Path) -> bool:
    if not pth.exists():
        return False
    md5 = fileMd5(str(pth))
    if md5 == obj.e_tag.replace("\"", "") or md5 == obj.metadata.get("md5","").replace("\"", ""):
        return True
    else:
        return False


def fileMd5(file:str) -> str:
    hsh = hashlib.md5()
    with open(file, "rb") as f:
        for b in iter(lambda: f.read(65536), b""):
            hsh.update(b)
    return hsh.hexdigest()


def preparePath(pth:pathlib.Path) -> None:
    pth.parent.mkdir(parents=True, exist_ok=True)


def checkLocal(pth:pathlib.Path) -> Outcome:
    if pth.exists() and pth.stat().st_size > 0:
        return Success(str(pth))
    else:
        return Failure("Error downloading {}; local file does not exist or is empty".format(str(pth)))


# TODO: For both of these upload functions, should probably be doing something sane
# with ContentType and ContentEncoding
# -> Outcome[str, Union[str, S3Path]]
def uploadFile(localPath:pathlike, remotePath:Union[str, S3Path]) -> Outcome:
    s3path = S3Path(remotePath)
    try:
        obj = boto3.resource("s3").Object(s3path.bucket, s3path.key)
        if isCurrent(obj, pathlib.Path(localPath)):
            return Success(localPath)
        else:
            obj.upload_file(str(localPath))
            return Success(localPath)
    except Exception as err:
        return Failure("Unable to upload {} to {}. Reason: {}"
                        .format(str(localPath), str(remotePath), err))


# -> Outcome[str, Union[str, S3Path]]
def uploadData(data:AnyStr, remotePath:Union[str, S3Path]) -> Outcome:
    s3path = S3Path(remotePath)
    try:
        obj = boto3.resource("s3").Object(s3path.bucket, s3path.key)
        if isinstance(data, str):
            bData = data.encode()
        else:
            bData = data
        hsh = hashlib.md5()
        hsh.update(bData)
        md5 = hsh.hexdigest()
        obj.put(Body=bData, ContentMD5=md5)
        return Success(remotePath)
    except Exception as err:
        return Failure("Unable to upload data to {}. Reason: {}"
                        .format(str(s3path), err))
